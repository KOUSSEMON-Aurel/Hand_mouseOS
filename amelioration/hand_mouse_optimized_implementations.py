#!/usr/bin/env python3
"""
Hand Mouse OS - Code d'Optimisation Complet
===========================================
Impl√©mentations pr√™tes √† l'emploi pour toutes les optimisations
"""

import time
import threading
import numpy as np
import cv2
from collections import deque
from dataclasses import dataclass
from typing import Optional, Tuple, List
import uinput


# ============================================================================
# 1. PROFILING & METRICS
# ============================================================================

class PerformanceProfiler:
    """Profiler pour mesurer pr√©cis√©ment les temps de chaque √©tape"""
    
    def __init__(self, window_size=100):
        self.metrics = {
            'capture': deque(maxlen=window_size),
            'preprocess': deque(maxlen=window_size),
            'inference': deque(maxlen=window_size),
            'postprocess': deque(maxlen=window_size),
            'total': deque(maxlen=window_size),
        }
        self.timestamps = {}
    
    def mark(self, event_name: str):
        """Marquer un timestamp"""
        self.timestamps[event_name] = time.perf_counter()
    
    def measure(self, stage: str, start: str, end: str):
        """Calculer et enregistrer la dur√©e d'une √©tape"""
        if start in self.timestamps and end in self.timestamps:
            duration_ms = (self.timestamps[end] - self.timestamps[start]) * 1000
            self.metrics[stage].append(duration_ms)
    
    def get_stats(self, stage: str) -> dict:
        """Obtenir les statistiques d'une √©tape"""
        if not self.metrics[stage]:
            return {'avg': 0, 'min': 0, 'max': 0, 'p95': 0}
        
        data = list(self.metrics[stage])
        return {
            'avg': np.mean(data),
            'min': np.min(data),
            'max': np.max(data),
            'p95': np.percentile(data, 95),
        }
    
    def print_report(self):
        """Afficher un rapport de performance"""
        print("\n" + "="*60)
        print("üìä RAPPORT DE PERFORMANCE")
        print("="*60)
        
        for stage in ['capture', 'preprocess', 'inference', 'postprocess', 'total']:
            stats = self.get_stats(stage)
            print(f"\n{stage.upper():>15}: "
                  f"Avg={stats['avg']:6.2f}ms  "
                  f"Min={stats['min']:6.2f}ms  "
                  f"Max={stats['max']:6.2f}ms  "
                  f"P95={stats['p95']:6.2f}ms")
        
        # Calcul FPS
        if self.metrics['total']:
            avg_frame_time = np.mean(list(self.metrics['total']))
            fps = 1000 / avg_frame_time if avg_frame_time > 0 else 0
            print(f"\n{'FPS':>15}: {fps:.1f}")
        
        print("="*60 + "\n")


# ============================================================================
# 2. RING BUFFER LATEST-ONLY
# ============================================================================

class LatestFrameBuffer:
    """Buffer qui garde uniquement la frame la plus r√©cente"""
    
    def __init__(self):
        self.frame = None
        self.lock = threading.Lock()
        self.new_frame_available = threading.Event()
        self.frame_count = 0
        self.dropped_count = 0
    
    def put(self, frame: np.ndarray):
        """D√©poser une frame (√©crase l'ancienne si non consomm√©e)"""
        with self.lock:
            if self.frame is not None and not self.new_frame_available.is_set():
                # Frame pr√©c√©dente pas encore consomm√©e = drop
                self.dropped_count += 1
            
            self.frame = frame.copy()
            self.frame_count += 1
            self.new_frame_available.set()
    
    def get(self, timeout: float = 0.1) -> Optional[np.ndarray]:
        """R√©cup√©rer la derni√®re frame disponible"""
        if self.new_frame_available.wait(timeout):
            with self.lock:
                frame = self.frame
                self.new_frame_available.clear()
                return frame
        return None
    
    def get_stats(self) -> dict:
        """Statistiques du buffer"""
        return {
            'total_frames': self.frame_count,
            'dropped_frames': self.dropped_count,
            'drop_rate': (self.dropped_count / self.frame_count * 100) 
                        if self.frame_count > 0 else 0
        }


# ============================================================================
# 3. ADAPTIVE ONE EURO FILTER
# ============================================================================

class OneEuroFilter:
    """Implementation du filtre 1‚Ç¨ classique"""
    
    def __init__(self, min_cutoff=0.004, beta=0.7, d_cutoff=1.0):
        self.min_cutoff = min_cutoff
        self.beta = beta
        self.d_cutoff = d_cutoff
        self.x_prev = None
        self.dx_prev = 0.0
        self.t_prev = None
    
    def __call__(self, x: float, timestamp: float) -> float:
        if self.x_prev is None:
            self.x_prev = x
            self.t_prev = timestamp
            return x
        
        # Calculer la fr√©quence
        dt = timestamp - self.t_prev
        if dt <= 0:
            return self.x_prev
        
        freq = 1.0 / dt
        
        # Filtrer la d√©riv√©e
        dx = (x - self.x_prev) * freq
        edx = self._smoothing_factor(freq, self.d_cutoff)
        dx_filtered = self._exponential_smoothing(edx, dx, self.dx_prev)
        
        # Filtrer la position
        cutoff = self.min_cutoff + self.beta * abs(dx_filtered)
        ex = self._smoothing_factor(freq, cutoff)
        x_filtered = self._exponential_smoothing(ex, x, self.x_prev)
        
        # Sauvegarder l'√©tat
        self.x_prev = x_filtered
        self.dx_prev = dx_filtered
        self.t_prev = timestamp
        
        return x_filtered
    
    @staticmethod
    def _smoothing_factor(freq: float, cutoff: float) -> float:
        r = 2 * np.pi * cutoff / freq
        return r / (r + 1)
    
    @staticmethod
    def _exponential_smoothing(alpha: float, x: float, x_prev: float) -> float:
        return alpha * x + (1 - alpha) * x_prev


class AdaptiveOneEuroFilter:
    """Version adaptative qui ajuste min_cutoff selon la vitesse"""
    
    def __init__(self):
        self.filter_x = OneEuroFilter(min_cutoff=0.004, beta=0.7)
        self.filter_y = OneEuroFilter(min_cutoff=0.004, beta=0.7)
        self.prev_pos = None
        self.prev_time = None
        
        # Seuils de vitesse (pixels/seconde)
        self.FAST_THRESHOLD = 800
        self.MEDIUM_THRESHOLD = 300
        
        # Param√®tres de filtrage selon vitesse
        self.FAST_CUTOFF = 0.001      # Tr√®s r√©actif
        self.MEDIUM_CUTOFF = 0.004    # √âquilibr√©
        self.SLOW_CUTOFF = 0.010      # Tr√®s stable
    
    def __call__(self, x: float, y: float, timestamp: float) -> Tuple[float, float]:
        """Filtrer avec adaptation dynamique"""
        
        # Calculer la vitesse si possible
        if self.prev_pos is not None and self.prev_time is not None:
            dt = timestamp - self.prev_time
            if dt > 0:
                dx = x - self.prev_pos[0]
                dy = y - self.prev_pos[1]
                speed = np.sqrt(dx**2 + dy**2) / dt
                
                # Adapter le min_cutoff selon la vitesse
                if speed > self.FAST_THRESHOLD:
                    cutoff = self.FAST_CUTOFF
                elif speed > self.MEDIUM_THRESHOLD:
                    cutoff = self.MEDIUM_CUTOFF
                else:
                    cutoff = self.SLOW_CUTOFF
                
                # Mise √† jour douce du cutoff pour √©viter les saccades
                self.filter_x.min_cutoff = (0.7 * self.filter_x.min_cutoff + 
                                           0.3 * cutoff)
                self.filter_y.min_cutoff = (0.7 * self.filter_y.min_cutoff + 
                                           0.3 * cutoff)
        
        # Appliquer le filtre
        x_filtered = self.filter_x(x, timestamp)
        y_filtered = self.filter_y(y, timestamp)
        
        # Sauvegarder pour calcul vitesse
        self.prev_pos = (x, y)
        self.prev_time = timestamp
        
        return x_filtered, y_filtered


# ============================================================================
# 4. CAMERA CONFIGURATION
# ============================================================================

class CameraConfigurator:
    """Configuration optimale de la cam√©ra avec v4l2"""
    
    @staticmethod
    def list_cameras():
        """Lister les cam√©ras disponibles"""
        import subprocess
        result = subprocess.run(['v4l2-ctl', '--list-devices'],
                              capture_output=True, text=True)
        print(result.stdout)
    
    @staticmethod
    def get_controls(device='/dev/video0'):
        """Obtenir les contr√¥les disponibles"""
        import subprocess
        result = subprocess.run(['v4l2-ctl', '-d', device, '--list-ctrls'],
                              capture_output=True, text=True)
        return result.stdout
    
    @staticmethod
    def configure_camera(device='/dev/video0', 
                        exposure_auto=1,
                        exposure_absolute=150,
                        focus_auto=0,
                        focus_absolute=0,
                        gain=100):
        """
        Configure la cam√©ra pour performance optimale
        
        Args:
            device: Chemin du device (ex: /dev/video0)
            exposure_auto: 1=manuel, 3=auto
            exposure_absolute: Valeur d'exposition (100-500 typique)
            focus_auto: 0=manuel, 1=auto
            focus_absolute: Distance de focus (0-255)
            gain: Gain ISO (0-255)
        """
        import subprocess
        
        commands = [
            f'v4l2-ctl -d {device} --set-ctrl=exposure_auto={exposure_auto}',
            f'v4l2-ctl -d {device} --set-ctrl=exposure_absolute={exposure_absolute}',
        ]
        
        # Focus (si support√©)
        if focus_auto is not None:
            commands.append(f'v4l2-ctl -d {device} --set-ctrl=focus_auto={focus_auto}')
        if focus_absolute is not None:
            commands.append(f'v4l2-ctl -d {device} --set-ctrl=focus_absolute={focus_absolute}')
        
        # Gain
        if gain is not None:
            commands.append(f'v4l2-ctl -d {device} --set-ctrl=gain={gain}')
        
        # White balance manuel (√©viter les variations)
        commands.extend([
            f'v4l2-ctl -d {device} --set-ctrl=white_balance_temperature_auto=0',
            f'v4l2-ctl -d {device} --set-ctrl=white_balance_temperature=4600',
        ])
        
        for cmd in commands:
            try:
                subprocess.run(cmd.split(), check=False, 
                             capture_output=True, text=True)
            except Exception as e:
                print(f"‚ö†Ô∏è  Commande √©chou√©e: {cmd}")
                print(f"   Erreur: {e}")
        
        print("‚úÖ Cam√©ra configur√©e")
    
    @staticmethod
    def create_optimized_capture(device_id=0, width=640, height=480, fps=30):
        """
        Cr√©er un VideoCapture optimis√© avec GStreamer si disponible
        """
        # Essayer GStreamer d'abord
        try:
            pipeline = (
                f'v4l2src device=/dev/video{device_id} ! '
                f'video/x-raw,format=YUY2,width={width},height={height},'
                f'framerate={fps}/1 ! '
                'videoconvert ! '
                'video/x-raw,format=BGR ! '
                'appsink'
            )
            cap = cv2.VideoCapture(pipeline, cv2.CAP_GSTREAMER)
            if cap.isOpened():
                print("‚úÖ Pipeline GStreamer activ√©")
                return cap
        except:
            pass
        
        # Fallback sur OpenCV standard
        cap = cv2.VideoCapture(device_id)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
        cap.set(cv2.CAP_PROP_FPS, fps)
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # Buffer minimal
        
        print("‚ö†Ô∏è  Pipeline OpenCV standard (pas GStreamer)")
        return cap


# ============================================================================
# 5. PREALLOCATED BUFFERS
# ============================================================================

class PreallocatedBuffers:
    """Gestionnaire de buffers pr√©allou√©s pour √©viter copies"""
    
    def __init__(self, width=640, height=480):
        self.width = width
        self.height = height
        
        # Buffers principaux
        self.capture_buffer = np.empty((height, width, 3), dtype=np.uint8)
        self.rgb_buffer = np.empty((height, width, 3), dtype=np.uint8)
        self.gray_buffer = np.empty((height, width), dtype=np.uint8)
        
        # Buffer pour resize (si n√©cessaire)
        self.resize_buffer = None
    
    def get_capture_buffer(self) -> np.ndarray:
        """Retourne le buffer de capture"""
        return self.capture_buffer
    
    def convert_to_rgb_inplace(self, bgr_frame: np.ndarray) -> np.ndarray:
        """Conversion BGR‚ÜíRGB in-place"""
        cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2RGB, dst=self.rgb_buffer)
        return self.rgb_buffer
    
    def convert_to_gray_inplace(self, bgr_frame: np.ndarray) -> np.ndarray:
        """Conversion BGR‚ÜíGRAY in-place"""
        cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2GRAY, dst=self.gray_buffer)
        return self.gray_buffer
    
    def resize_inplace(self, frame: np.ndarray, 
                      target_width: int, 
                      target_height: int) -> np.ndarray:
        """Resize in-place dans un buffer d√©di√©"""
        if (self.resize_buffer is None or 
            self.resize_buffer.shape[:2] != (target_height, target_width)):
            channels = frame.shape[2] if len(frame.shape) == 3 else 1
            self.resize_buffer = np.empty((target_height, target_width, channels), 
                                         dtype=frame.dtype)
        
        cv2.resize(frame, (target_width, target_height),
                  dst=self.resize_buffer,
                  interpolation=cv2.INTER_LINEAR)
        return self.resize_buffer


# ============================================================================
# 6. DWELL CLICK DETECTOR
# ============================================================================

class DwellClickDetector:
    """D√©tecteur de clic par maintien de position"""
    
    def __init__(self, dwell_time=0.4, tolerance_px=15):
        self.dwell_time = dwell_time
        self.tolerance = tolerance_px
        self.dwell_start = None
        self.dwell_pos = None
        self.in_dwell = False
    
    def update(self, x: float, y: float, timestamp: float) -> Tuple[bool, float]:
        """
        Mise √† jour du d√©tecteur
        
        Returns:
            (click_detected, progress): click_detected est True si clic confirm√©,
                                       progress est entre 0.0 et 1.0
        """
        if self.dwell_pos is None:
            # Premier point
            self.dwell_pos = (x, y)
            self.dwell_start = timestamp
            self.in_dwell = True
            return False, 0.0
        
        # Calculer distance depuis point de d√©part
        distance = np.sqrt((x - self.dwell_pos[0])**2 + 
                          (y - self.dwell_pos[1])**2)
        
        if distance > self.tolerance:
            # Mouvement d√©tect√© ‚Üí reset
            self.dwell_pos = (x, y)
            self.dwell_start = timestamp
            self.in_dwell = True
            return False, 0.0
        
        # Calculer progression
        elapsed = timestamp - self.dwell_start
        progress = min(elapsed / self.dwell_time, 1.0)
        
        if elapsed >= self.dwell_time:
            # Clic d√©tect√©!
            self.dwell_pos = None
            self.in_dwell = False
            return True, 1.0
        
        return False, progress
    
    def reset(self):
        """R√©initialiser le d√©tecteur"""
        self.dwell_pos = None
        self.dwell_start = None
        self.in_dwell = False


# ============================================================================
# 7. VISUAL FEEDBACK
# ============================================================================

class VisualFeedback:
    """Rendu de feedback visuel pour l'utilisateur"""
    
    @staticmethod
    def draw_dwell_progress(frame: np.ndarray, 
                           x: int, y: int, 
                           progress: float,
                           radius: int = 30):
        """Dessiner cercle de progression pour dwell click"""
        # Cercle de fond
        cv2.circle(frame, (x, y), radius, (50, 50, 50), 2)
        
        # Arc de progression
        if progress > 0:
            angle = int(360 * progress)
            # Couleur: vert ‚Üí jaune ‚Üí rouge selon progression
            if progress < 0.5:
                color = (0, 255, 0)  # Vert
            elif progress < 0.8:
                color = (0, 255, 255)  # Jaune
            else:
                color = (0, 165, 255)  # Orange
            
            cv2.ellipse(frame, (x, y), (radius, radius),
                       -90, 0, angle, color, 3)
        
        # Point central
        cv2.circle(frame, (x, y), 5, (255, 255, 255), -1)
    
    @staticmethod
    def draw_hand_skeleton(frame: np.ndarray, 
                          landmarks: List[Tuple[int, int]],
                          connections: List[Tuple[int, int]] = None):
        """Dessiner le squelette de la main"""
        if connections is None:
            # Connexions standards MediaPipe
            connections = [
                (0, 1), (1, 2), (2, 3), (3, 4),  # Pouce
                (0, 5), (5, 6), (6, 7), (7, 8),  # Index
                (0, 9), (9, 10), (10, 11), (11, 12),  # Majeur
                (0, 13), (13, 14), (14, 15), (15, 16),  # Annulaire
                (0, 17), (17, 18), (18, 19), (19, 20),  # Auriculaire
                (5, 9), (9, 13), (13, 17)  # Paume
            ]
        
        # Dessiner les connexions
        for start_idx, end_idx in connections:
            if start_idx < len(landmarks) and end_idx < len(landmarks):
                pt1 = landmarks[start_idx]
                pt2 = landmarks[end_idx]
                cv2.line(frame, pt1, pt2, (0, 255, 0), 2)
        
        # Dessiner les points
        for point in landmarks:
            cv2.circle(frame, point, 4, (255, 0, 0), -1)
    
    @staticmethod
    def draw_fps(frame: np.ndarray, fps: float):
        """Afficher les FPS"""
        text = f"FPS: {fps:.1f}"
        cv2.putText(frame, text, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    
    @staticmethod
    def draw_status(frame: np.ndarray, status: str, color=(0, 255, 0)):
        """Afficher un message de statut"""
        cv2.putText(frame, status, (10, 60),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)


# ============================================================================
# 8. CALIBRATION SYSTEM
# ============================================================================

class CalibrationSystem:
    """Syst√®me de calibration 4-points pour mapping cam√©ra‚Üí√©cran"""
    
    def __init__(self, screen_width: int, screen_height: int):
        self.screen_width = screen_width
        self.screen_height = screen_height
        self.transform_matrix = None
        self.is_calibrated = False
    
    def calibrate(self, camera_points: List[Tuple[float, float]]) -> bool:
        """
        Effectuer la calibration
        
        Args:
            camera_points: 4 points d√©tect√©s par la cam√©ra 
                          [top-left, top-right, bottom-right, bottom-left]
        
        Returns:
            True si succ√®s
        """
        if len(camera_points) != 4:
            return False
        
        # Points cibles √† l'√©cran (coins)
        screen_points = [
            (0, 0),
            (self.screen_width, 0),
            (self.screen_width, self.screen_height),
            (0, self.screen_height)
        ]
        
        # Convertir en numpy
        src_pts = np.float32(camera_points)
        dst_pts = np.float32(screen_points)
        
        # Calculer transformation perspective
        self.transform_matrix = cv2.getPerspectiveTransform(src_pts, dst_pts)
        self.is_calibrated = True
        
        return True
    
    def apply(self, x: float, y: float) -> Tuple[float, float]:
        """Appliquer la transformation calibr√©e"""
        if not self.is_calibrated:
            # Pas calibr√© ‚Üí mapping simple
            return x * self.screen_width, y * self.screen_height
        
        # Appliquer transformation perspective
        point = np.array([[[x, y]]], dtype=np.float32)
        transformed = cv2.perspectiveTransform(point, self.transform_matrix)
        
        return float(transformed[0][0][0]), float(transformed[0][0][1])
    
    def save(self, filepath: str):
        """Sauvegarder la calibration"""
        if self.is_calibrated:
            np.save(filepath, self.transform_matrix)
    
    def load(self, filepath: str) -> bool:
        """Charger une calibration"""
        try:
            self.transform_matrix = np.load(filepath)
            self.is_calibrated = True
            return True
        except:
            return False


# ============================================================================
# 9. ADAPTIVE SENSITIVITY MAPPING
# ============================================================================

class AdaptiveSensitivityMapper:
    """Mapping non-lin√©aire avec sensibilit√© adaptative"""
    
    def __init__(self, screen_width: int, screen_height: int, gamma=1.3):
        self.screen_width = screen_width
        self.screen_height = screen_height
        self.gamma = gamma
        self.deadzone = 0.05  # 5% au centre
    
    def map(self, x_normalized: float, y_normalized: float) -> Tuple[float, float]:
        """
        Mapper coordonn√©es normalis√©es [0,1] vers √©cran avec courbe adaptative
        
        Args:
            x_normalized, y_normalized: Coordonn√©es entre 0 et 1
        
        Returns:
            (x_screen, y_screen): Coordonn√©es √©cran en pixels
        """
        # Normaliser [-1, 1] centr√©
        x_centered = (x_normalized - 0.5) * 2
        y_centered = (y_normalized - 0.5) * 2
        
        # Appliquer deadzone centrale
        if abs(x_centered) < self.deadzone:
            x_mapped = 0
        else:
            # Courbe expo: plus de contr√¥le au centre
            x_mapped = np.sign(x_centered) * (abs(x_centered) ** self.gamma)
        
        if abs(y_centered) < self.deadzone:
            y_mapped = 0
        else:
            y_mapped = np.sign(y_centered) * (abs(y_centered) ** self.gamma)
        
        # Reconvertir en coordonn√©es √©cran
        x_screen = (x_mapped / 2 + 0.5) * self.screen_width
        y_screen = (y_mapped / 2 + 0.5) * self.screen_height
        
        # Clamp
        x_screen = np.clip(x_screen, 0, self.screen_width - 1)
        y_screen = np.clip(y_screen, 0, self.screen_height - 1)
        
        return x_screen, y_screen


# ============================================================================
# 10. UINPUT MOUSE DRIVER (Optimis√©)
# ============================================================================

class OptimizedMouseDriver:
    """Driver souris optimis√© avec √©v√©nements absolus"""
    
    def __init__(self, screen_width: int, screen_height: int):
        self.screen_width = screen_width
        self.screen_height = screen_height
        
        # Cr√©er device uinput avec √©v√©nements absolus
        events = (
            uinput.EV_ABS + (
                (uinput.ABS_X, (0, screen_width, 0, 0)),
                (uinput.ABS_Y, (0, screen_height, 0, 0)),
            ),
            uinput.BTN_LEFT,
            uinput.BTN_RIGHT,
            uinput.BTN_MIDDLE,
        )
        
        self.device = uinput.Device(events, name='HandMouseOS-Optimized')
        print("‚úÖ Device virtuel cr√©√©: HandMouseOS-Optimized")
    
    def move(self, x: int, y: int):
        """D√©placer le curseur (coordonn√©es absolues)"""
        x = int(np.clip(x, 0, self.screen_width - 1))
        y = int(np.clip(y, 0, self.screen_height - 1))
        
        # √âv√©nements absolus pour pr√©cision maximale
        self.device.emit(uinput.ABS_X, x, syn=False)
        self.device.emit(uinput.ABS_Y, y, syn=True)
    
    def click(self, button='left'):
        """Effectuer un clic"""
        btn_map = {
            'left': uinput.BTN_LEFT,
            'right': uinput.BTN_RIGHT,
            'middle': uinput.BTN_MIDDLE,
        }
        
        btn = btn_map.get(button, uinput.BTN_LEFT)
        
        # Clic = press + release
        self.device.emit(btn, 1)  # Press
        self.device.emit(btn, 0)  # Release
    
    def press(self, button='left'):
        """Presser un bouton (sans rel√¢cher)"""
        btn_map = {
            'left': uinput.BTN_LEFT,
            'right': uinput.BTN_RIGHT,
            'middle': uinput.BTN_MIDDLE,
        }
        btn = btn_map.get(button, uinput.BTN_LEFT)
        self.device.emit(btn, 1)
    
    def release(self, button='left'):
        """Rel√¢cher un bouton"""
        btn_map = {
            'left': uinput.BTN_LEFT,
            'right': uinput.BTN_RIGHT,
            'middle': uinput.BTN_MIDDLE,
        }
        btn = btn_map.get(button, uinput.BTN_LEFT)
        self.device.emit(btn, 0)
    
    def close(self):
        """Fermer le device"""
        if hasattr(self, 'device'):
            del self.device


# ============================================================================
# 11. EXEMPLE D'INT√âGRATION COMPL√àTE
# ============================================================================

def example_optimized_pipeline():
    """
    Exemple d'utilisation de tous les composants ensemble
    """
    import screeninfo
    
    # Configuration
    CAMERA_ID = 0
    CAMERA_WIDTH = 640
    CAMERA_HEIGHT = 480
    CAMERA_FPS = 30
    
    # Obtenir r√©solution √©cran
    screen = screeninfo.get_monitors()[0]
    SCREEN_WIDTH = screen.width
    SCREEN_HEIGHT = screen.height
    
    print("="*60)
    print("üöÄ HAND MOUSE OS - Pipeline Optimis√©")
    print("="*60)
    print(f"√âcran: {SCREEN_WIDTH}x{SCREEN_HEIGHT}")
    print(f"Cam√©ra: {CAMERA_WIDTH}x{CAMERA_HEIGHT} @ {CAMERA_FPS}fps")
    print("="*60 + "\n")
    
    # Initialisation composants
    profiler = PerformanceProfiler()
    frame_buffer = LatestFrameBuffer()
    buffers = PreallocatedBuffers(CAMERA_WIDTH, CAMERA_HEIGHT)
    cursor_filter = AdaptiveOneEuroFilter()
    dwell_detector = DwellClickDetector()
    calibration = CalibrationSystem(SCREEN_WIDTH, SCREEN_HEIGHT)
    sensitivity_mapper = AdaptiveSensitivityMapper(SCREEN_WIDTH, SCREEN_HEIGHT)
    mouse = OptimizedMouseDriver(SCREEN_WIDTH, SCREEN_HEIGHT)
    
    # Configuration cam√©ra
    print("‚öôÔ∏è  Configuration de la cam√©ra...")
    CameraConfigurator.configure_camera(
        device='/dev/video0',
        exposure_absolute=150,
        gain=100
    )
    
    # Ouvrir cam√©ra
    cap = CameraConfigurator.create_optimized_capture(
        CAMERA_ID, CAMERA_WIDTH, CAMERA_HEIGHT, CAMERA_FPS
    )
    
    if not cap.isOpened():
        print("‚ùå Impossible d'ouvrir la cam√©ra")
        return
    
    print("\n‚úÖ Syst√®me pr√™t!")
    print("üëã Montrez votre main devant la cam√©ra")
    print("‚è±Ô∏è  Maintenez position 0.4s pour cliquer")
    print("üî¥ Appuyez sur 'q' pour quitter\n")
    
    # Boucle principale
    try:
        frame_count = 0
        last_report_time = time.time()
        
        while True:
            profiler.mark('start')
            
            # Capture
            ret, frame = cap.read()
            if not ret:
                continue
            
            profiler.mark('captured')
            profiler.measure('capture', 'start', 'captured')
            
            # D√©poser dans buffer (pour d√©couplage si multiprocessing)
            frame_buffer.put(frame)
            
            # TODO: Ici, int√©grer MediaPipe inference
            # Pour l'exemple, on simule des coordonn√©es
            # hand_detected = True
            # hand_x, hand_y = 0.5, 0.5  # Coordonn√©es normalis√©es [0,1]
            
            profiler.mark('inferred')
            profiler.measure('inference', 'captured', 'inferred')
            
            # Filtrage & mapping
            timestamp = time.time()
            # filtered_x, filtered_y = cursor_filter(hand_x, hand_y, timestamp)
            # screen_x, screen_y = sensitivity_mapper.map(filtered_x, filtered_y)
            
            profiler.mark('filtered')
            profiler.measure('postprocess', 'inferred', 'filtered')
            
            # D√©tection clic
            # click_detected, progress = dwell_detector.update(
            #     screen_x, screen_y, timestamp
            # )
            
            # if click_detected:
            #     mouse.click('left')
            # else:
            #     mouse.move(int(screen_x), int(screen_y))
            
            # Feedback visuel
            display_frame = frame.copy()
            VisualFeedback.draw_fps(display_frame, 
                                   1000 / profiler.get_stats('total')['avg']
                                   if profiler.metrics['total'] else 0)
            
            cv2.imshow('Hand Mouse OS', display_frame)
            
            profiler.mark('end')
            profiler.measure('total', 'start', 'end')
            
            # Rapport toutes les 5 secondes
            frame_count += 1
            if time.time() - last_report_time > 5.0:
                profiler.print_report()
                buffer_stats = frame_buffer.get_stats()
                print(f"üìä Frames dropp√©es: {buffer_stats['dropped_frames']} "
                      f"({buffer_stats['drop_rate']:.1f}%)\n")
                last_report_time = time.time()
            
            # Gestion clavier
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
    
    finally:
        cap.release()
        cv2.destroyAllWindows()
        mouse.close()
        print("\n‚úÖ Arr√™t propre du syst√®me")


if __name__ == '__main__':
    print(__doc__)
    print("\n‚ö†Ô∏è  Ce fichier contient les impl√©mentations de r√©f√©rence.")
    print("Pour ex√©cuter l'exemple complet: d√©commentez la ligne ci-dessous\n")
    
    # D√©commenter pour tester:
    # example_optimized_pipeline()
